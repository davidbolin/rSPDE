---
title: "inlabru implementation of the rational SPDE approach"
author: "David Bolin and Alexandre B. Simas"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{inlabru implementation of the rational SPDE approach}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
references:
- id: bolin19
  title: "The rational SPDE approach for Gaussian random fields with general smoothness"
  author:
  - family: Bolin
    given: David
  - family: Kirchner
    given: Kristin
  container-title: Journal of Computational and Graphical Statistics
  volume: 29
  issue: 2
  page: 274-285
  type: article-journal
  issued:
    year: 2020
- id: lindgren11
  title: "An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach"
  author:
  - family: Lindgren
    given: Finn
  - family: Rue
    given: Håvard
  - family: Lindström
    given: Johan
  container-title: Journal of the Royal Statistical Society. Series B. Statistical Methodology
  volume: 73
  issue: 4
  page: 423--498
  type: article-journal
  issued:
    year: 2011
- id: xiong22
  title: "Covariance-based rational approximations of fractional SPDEs for computationally efficient Bayesian inference"
  author: 
  - family: Xiong
    given: Zhen
  - family: Simas
    give: Alexandre B.
  - family: Bolin
    given: David
  container-title: arXiv:2209.04670
  type: preprint
  issued:
    year: 2022
- id: Hofreither21
  title: "An algorithm for best rational approximation based on barycentric rational interpolation"
  author:
  - family: Hofreither
    given: Clemens
  container-title: Numerical Algorithms
  volume: 88
  issue: 1
  page: 365--388
  type: article-journal
  issued:
    year: 2021 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(1, kind = "Mersenne-Twister", normal.kind = "Inversion")
```

```{r inla_link, include = FALSE}
inla_link <- function() {
  sprintf("[%s](%s)", "`R-INLA`", "https://www.r-inla.org")
}
```

## Introduction 

In this vignette we will present the [`inlabru`](http://inlabru.org/) implementation of the covariance-based
rational SPDE approach. For further technical details on the covariance-based approach, see 
the [Rational approximation with the `rSPDE` package](rspde_cov.html) vignette
and [@xiong22](https://www.tandfonline.com/doi/full/10.1080/10618600.2019.1665537).

We begin by providing a 
step-by-step illustration on how to use our implementation. To this end we 
will consider a real world data set that consists of precipitation measurements 
from the Paraná region in Brazil. 

After the initial model fitting, we will show how to change some parameters of the model. In the end, we will also provide an example in which we have replicates.

The examples in this vignette are the same as those in the [R-INLA implementation of the rational SPDE approach](rspde_inla.html) vignette. 
As in that case, it is important to mention that one can improve the performance
by using the PARDISO solver. Please, go to https://www.pardiso-project.org/r-inla/#license
to apply for a license. Also, use `inla.pardiso()` for instructions on 
how to enable the PARDISO sparse library.

## An example with real data

To illustrate our implementation of `rSPDE` in [`inlabru`](http://inlabru.org/) we will consider a dataset
available in `r inla_link()`. This data has also been used to illustrate the SPDE approach,
see for instance the book [Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA](https://www.routledge.com/Advanced-Spatial-Modeling-with-Stochastic-Partial-Differential-Equations/Krainski-Gomez-Rubio-Bakka-Lenzi-Castro-Camilo-Simpson-Lindgren-Rue/p/book/9780367570644) and also the vignette [Spatial Statistics using R-INLA and Gaussian Markov random fields](https://sites.stat.washington.edu/peter/591/INLA.html).
See also [@lindgren11](https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1467-9868.2011.00777.x)
for theoretical details on the standard SPDE approach.

The data consist of precipitation measurements from the Paraná region in Brazil
and were provided by the Brazilian National Water Agency. The data were collected
at 616 gauge stations in Paraná state, south of Brazil, for each day in 2011.

### An rSPDE model for precipitation

We will follow the vignette [Spatial Statistics using R-INLA and Gaussian Markov random fields](https://sites.stat.washington.edu/peter/591/INLA.html). 
As precipitation data are always positive, we will assume it is Gamma distributed. 
`r inla_link()` uses the following parameterization of the Gamma distribution, 
$$\Gamma(\mu, \phi): \pi (y) = \frac{1}{\Gamma(\phi)} \left(\frac{\phi}{\mu}\right)^{\phi} y^{\phi - 1} \exp\left(-\frac{\phi y}{\mu}\right) .$$
In this parameterization, the distribution has expected value $E(x) = \mu$ and variance $V(x) = \mu^2/\phi$, where $1/\phi$ is a dispersion parameter.

In this example $\mu$ will be modelled using a stochastic model that includes both covariates 
and spatial structure, resulting in the latent Gaussian model for the precipitation measurements
$$\begin{align} y_i\mid \mu(s_i), \theta &\sim \Gamma(\mu(s_i),c\phi)\\ \log (\mu(s)) &= \eta(s) = \sum_k f_k(c_k(s))+u(s)\\ \theta &\sim \pi(\theta) \end{align},$$

where $y_i$ denotes the measurement taken at location $s_i$, $c_k(s)$ are covariates, $u(s)$ is a mean-zero Gaussian Matérn field, and $\theta$ is a vector containing all parameters of the model,
including smoothness of the field. That is, by using the `rSPDE` model we will 
also be able to estimate the smoothness of the latent field.

### Examining the data
We will be using [`inlabru`](http://inlabru.org/). The `inlabru` package is available on CRAN and 
also on [GitHub](https://github.com/inlabru-org/inlabru).

We begin by loading some libraries we need to get the data and build the plots.

```{r library_loading, message=FALSE}
library(gridExtra)
library(ggplot2)
library(lattice)
library(INLA)
library(inlabru)
library(splancs)
library(fields)
```

Let us load the data and the border of the region

```{r getting_data, message=FALSE}
data(PRprec)
data(PRborder)
```

The data frame contains daily measurements at 616 stations for the year 2011, as well as coordinates and altitude information for the measurement stations.
We will not analyze the full spatio-temporal data set, but instead look at the total precipitation in January, which we calculate as

```{r getting_january, message=FALSE}
Y <- rowMeans(PRprec[, 3 + 1:31])
```

In the next snippet of code, we extract the coordinates and altitudes 
and remove the locations with missing values.

```{r cleaning_data, message=FALSE}
ind <- !is.na(Y)
Y <- Y[ind]
coords <- as.matrix(PRprec[ind, 1:2])
alt <- PRprec$Altitude[ind]
```

Let us build a plot for the precipitations:

```{r plot_precipitations, message=FALSE, fig.align = "center", echo=FALSE}
p <- ggplot() +
  geom_point(aes(
    x = coords[, 1], y = coords[, 2],
    colour = Y
  ), size = 2, alpha = 1) +
  scale_colour_gradientn(colours = tim.colors(100)) +
  geom_path(aes(x = PRborder[, 1], y = PRborder[, 2])) +
  geom_path(aes(x = PRborder[1034:1078, 1], y = PRborder[
    1034:1078,
    2
  ]), colour = "red")
tryCatch(
  {
    print(p)
  },
  error = function(e) {
    print("Unable to build the plot")
  }
)
```

The red line in the figure shows the coast line, and we expect the distance to 
the coast to be a good covariate for precipitation. 

This covariate is not 
available, so let us calculate it for each observation location:

```{r getting_seaDist, message=FALSE}
seaDist <- apply(spDists(coords, PRborder[1034:1078, ],
  longlat = TRUE
), 1, min)
```

Now, let us plot the precipitation as a function of the possible covariates:

```{r plot_prec_as_func, message=FALSE, fig.width=7, fig.height=5, fig.align = "center"}
par(mfrow = c(2, 2))
plot(coords[, 1], Y, cex = 0.5, xlab = "Longitude")
plot(coords[, 2], Y, cex = 0.5, xlab = "Latitude")
plot(seaDist, Y, cex = 0.5, xlab = "Distance to sea")
plot(alt, Y, cex = 0.5, xlab = "Altitude")
par(mfrow = c(1, 1))
```


### Creating the rSPDE model

To use the [`inlabru`](http://inlabru.org/) implementation of the `rSPDE` model we need to load the functions:
```{r load_rspde_lib, message=FALSE}
library(rSPDE)
```

To create a `rSPDE` model, one would the `rspde.matern()` function in a similar fashion as one would
use the `inla.spde2.matern()` function. 

#### Mesh

We can use `r inla_link()` for creating the mesh. Let us create a mesh which is based 
on a non-convex hull to avoid adding many small triangles outside the domain 
of interest:

```{r mesh_creation, message=FALSE, fig.align='center'}
prdomain <- inla.nonconvex.hull(coords, -0.03, -0.05, resolution = c(100, 100))
prmesh <- inla.mesh.2d(boundary = prdomain, max.edge = c(0.45, 1), cutoff = 0.2)
plot(prmesh, asp = 1, main = "")
lines(PRborder, col = 3)
points(coords[, 1], coords[, 2], pch = 19, cex = 0.5, col = "red")
```


#### Setting up the data frame

In place of a `inla.stack`, we can set up a `data.frame()` to use [`inlabru`](http://inlabru.org/). We refer the
reader to vignettes in https://inlabru-org.github.io/inlabru/index.html for further details.

```{r}
prdata <- data.frame(long = coords[,1], lat = coords[,2], 
                        seaDist = inla.group(seaDist), y = Y)
coordinates(prdata) <- c("long","lat")
```

#### Setting up the rSPDE model

To set up an `rSPDE`model, all we need is the mesh. 
By default it will assume that we want to estimate the smoothness parameter $\nu$
and to do a covariance-based rational approximation of order 2.

Later in this vignette we will also see other options for setting up `rSPDE` models such as keeping
the smoothness parameter fixed and/or increasing the order of the covariance-based
rational approximation.

Therefore, to set up a model all we have to do is use the `rspde.matern()` function:

```{r create_model, message=FALSE}
rspde_model <- rspde.matern(mesh = prmesh)
```

Notice that this function is very reminiscent of `r inla_link()`'s `inla.spde2.matern()` function.

We will assume the following linkage between model components and observations 
$$\eta(s) \sim A x(s) + A \text{ Intercept} + \text{seaDist}.$$
$\eta(s)$ will then be used in the observation-likelihood, 
$$y_i\mid \eta(s_i),\theta \sim \Gamma(\exp(\eta (s_i)), c\phi).$$

### Model fitting

We will build a model using the distance to the sea $x_i$ 
as a covariate through an improper CAR(1) model with 
$\beta_{ij}=1(i\sim j)$, which `r inla_link()` calls a random walk of order 1.
We will fit it in `inlabru`'s  style. For `inlabru` version `2.5.3.9002` or higher
we can use the following compact synthax:

```{r create_formula, message=FALSE}
cmp <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
field(coordinates, model = rspde_model)
```

For the current CRAN version of `inlabru` (version 2.5.3), one should use:

```{r create_formula2, message=FALSE}
cmp <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
field(coordinates, model = rspde_model, mapper = bru_mapper(rspde_model))
```

To fit the model we simply use the `bru()` function:

```{r fit_model, message=FALSE, warning=FALSE}
rspde_fit <- bru(cmp, data = prdata,
  family = "Gamma",
  options = list(
    inla.mode = "experimental",
    control.inla = list(int.strategy = "eb"),
    verbose = FALSE)
)
```

### inlabru results

We can look at some summaries of the posterior distributions for the parameters, 
for example the fixed effects (i.e. the intercept) and the hyper-parameters 
(i.e. dispersion in the gamma likelihood, the precision of the RW1, 
and the parameters of the spatial field):

```{r get_summary}
summary(rspde_fit)
```

Let $\theta_1 = \textrm{Theta1}$, $\theta_2=\textrm{Theta2}$ and $\theta_3=\textrm{Theta3}$.
In terms of 
the SPDE
$$(\kappa^2 I - \Delta)^{\alpha/2}(\tau u) = \mathcal{W},$$
where $\alpha = \nu + d/2$, we have that
$$\tau = \exp(\theta_1),\quad \kappa = \exp(\theta_2), $$
and by default
$$\nu = 4\Big(\frac{\exp(\theta_3)}{1+\exp(\theta_3)}\Big).$$
The number 4 comes from the upper bound for $\nu$, which will be discussed later in this vignette. 

In general, we have
$$\nu = \nu_{UB}\Big(\frac{\exp(\theta_3)}{1+\exp(\theta_3)}\Big),$$
where $\nu_{UB}$ is the value of the upper bound for the smoothness parameter $\nu$.

Another choice for prior for $\nu$ is a truncated lognormal distribution and
will also be discussed later in this vignette.

### `rSPDE`-`INLA` results

We can obtain outputs with respect to parameters in the original scale by
using the function `rspde.result()`:

```{r get_result}
result_fit <- rspde.result(rspde_fit, "field", rspde_model)
summary(result_fit)
```

We can also plot the posterior densities:

```{r plot_post, fig.align='center'}
par(mfrow = c(1, 3))
plot(result_fit, caption = c("tau", "kappa", "nu"))
```

This function is reminiscent to the `inla.spde.result()` function with the main
difference that it has the `summary()` and `plot()` methods implemented.


### Predictions

Let us now obtain predictions (i.e. do kriging) of the expected precipitation on 
a dense grid in the region.

We begin by creating the grid in which we want to do the predictions. To this end,
we can use the `inla.mesh.projector()` function:


```{r create_proj_grid}
nxy <- c(150, 100)
projgrid <- inla.mesh.projector(prmesh,
  xlim = range(PRborder[, 1]),
  ylim = range(PRborder[, 2]), dims = nxy
)
```

This lattice contains 150 × 100 locations. 
One can easily change the resolution of the kriging prediction by changing `nxy`. 
Let us find the cells that are outside the region of interest so that we
do not plot the estimates there.

```{r get_inout}
xy.in <- inout(projgrid$lattice$loc, cbind(PRborder[, 1], PRborder[, 2]))
```

Let us plot the locations that we will do prediction:

```{r plot_prd, fig.align='center'}
coord.prd <- projgrid$lattice$loc[xy.in, ]
plot(coord.prd, type = "p", cex = 0.1)
lines(PRborder)
points(coords[, 1], coords[, 2], pch = 19, cex = 0.5, col = "red")
```

Let us now create a `data.frame()` of the coordinates:

```{r}
coord.prd.df <- data.frame(x1 = coord.prd[,1],
                            x2 = coord.prd[,2])
coordinates(coord.prd.df) <- c("x1", "x2")
```

Since we are using distance to the sea as a covariate, we also have to calculate this covariate for the prediction locations.
Finally, we add the prediction location to our prediction `data.frame()`, namely, `coord.prd.df`:

```{r pred_seaDist}
seaDist.prd <- apply(spDists(coord.prd,
  PRborder[1034:1078, ],
  longlat = TRUE
), 1, min)
coord.prd.df$seaDist <- seaDist.prd
```

```{r}
pred_obs <- predict(rspde_fit, coord.prd.df, 
        ~exp(Intercept + field + distSea))
```

Let us now build the data frame with the results:

```{r}
pred_df <- pred_obs@data
pred_df <- cbind(pred_df, pred_obs@coords)
```

Finally, we plot the results. First the predicted mean:

```{r, echo=FALSE, fig.align='center'}
p <- ggplot(pred_df, aes(x = x1, y = x2, fill = mean)) +
  geom_raster() +
  scale_fill_gradient(low = "yellow", high = "red")
p
```

Then, the std. deviations:

```{r plot_pred_sd_bru, fig.align='center', echo=FALSE}
p <- ggplot(pred_df, aes(x = x1, y = x2, fill = sd)) +
  geom_raster()
p
```

## Further options of the `inlabru` implementation

We will now discuss some of the arguments that were introduced in our
[`inlabru`](http://inlabru.org/) implementation of the rational approximation
 that are not present in
`r inla_link()`'s standard SPDE implementation. 

In each case we will provide an illustrative example.

### Changing the upper bound for the smoothness parameter

When we fit a `rspde.matern()` model we need to provide an upper bound
for the smoothness parameter $\nu$. The reason for that is that the sparsity
of the precision matrix should be kept fixed during 
`r inla_link()`'s estimation and the higher
the value of $\nu$ the denser the precision matrix gets. 

This means that the higher the value of $\nu$, the higher the computational cost
to fit the model. Therefore, ideally, want to choose an upper bound for $\nu$
as small as possible. 

To change the value of the upper bound for the smoothness parameter, we must
change the argument `nu_upper_bound`. The default value for `nu_upper_bound` is
4. Other common choices for `nu_upper_bound` are 2 and 1.

It is clear from the discussion above that the smaller the value of `nu_upper_bound`
the faster the estimation procedure will be. 

However, if we choose a value of `nu_upper_bound` which is too low, the "correct"
value of $\nu$ might not belong to the interval $(0,\nu_{UB})$, where $\nu_{UB}$ is
the value of `nu_upper_bound`. Hence, one might be forced to increase `nu_upper_bound`
and estimate again, which, obviously will increase the computational cost as we will need
to do more than one estimation.

Let us illustrate by considering the same model we considered above for the precipitation
in Paraná region in Brazil and consider `nu_upper_bound` equal to 2, which is generally
a good choice for `nu_upper_bound`.

We simply use the function `rspde.matern()` with the argument `nu_upper_bound` set to 2:

```{r create_model_ub}
rspde_model_2 <- rspde.matern(mesh = prmesh, nu_upper_bound = 2)
```

Let us fit the above model:

```{r formula_fit_rspde_ub, message=FALSE, warning=FALSE}
# For inlabru 2.5.3.9002 or above:
cmp2 <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
field(coordinates, model = rspde_model_2)

# For inlabru 2.5.3:
cmp2 <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
field(coordinates, model = rspde_model_2, mapper=bru_mapper(rspde_model_2))

rspde_fit_2 <- bru(cmp2,
  family = "Gamma", data = prdata,
  options=list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(compute = TRUE),
            inla.mode = "experimental")
)
```

Let us see the summary of the fit:

```{r summary_fit}
summary(rspde_fit_2)
```

Let us compare with the cost from the previous fit, with the default value
of `nu_upper_bound` of 4:

```{r}
# nu_upper_bound = 4
rspde_fit$cpu.used
# nu_upper_bound = 2
rspde_fit_2$cpu.used
```

We can see that the fit for `nu_upper_bound` equal to 2 was considerably faster.

Finally, let us get the result the user's scale and see the estimate for $\nu$:

```{r get_summary_results_ub}
result_fit_2 <- rspde.result(rspde_fit_2, "field", rspde_model_2)
summary(result_fit_2)
```

### Changing the order of the rational approximation

To change the order of the rational approximation all we have to do
is set the argument `rspde_order` to the desired value. The current available
possibilities are `1,2,3`,..., up to `8`. 

The higher the order of the rational approximation, the more accurate the results
will be, however, the higher the computational cost will be.

The default `rspde_order` of 2 is generally a good choice and reasonably
accurate. See the vignette [Rational approximation with the rSPDE package](rspde_cov.html)
for further details on the order of the rational approximation and some comparison
with the Matérn covariance.

Let us fit the above model with the covariance-based rational approximation
of order `3`.

* We build a new model:
```{r model_order_3, message=FALSE}
rspde_model_order_3 <- rspde.matern(mesh = prmesh, 
  rspde_order = 3,
  nu_upper_bound = 2
)
```

* Now, we fit the model:

```{r}
# For inlabru 2.5.3.9002 or above:
cmp3 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3)

# For inlabru 2.5.3:
cmp3 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3, 
  mapper = bru_mapper(rspde_model_order_3))


rspde_fit_order_3 <- bru(cmp3,
  data = prdata,
  family = "Gamma",
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(compute = TRUE),
            inla.mode = "experimental")
)
```

Let us see the summary:
```{r summary_order_3}
summary(rspde_fit_order_3)
```

Let us compare the cost of having `rspde_order=3` and 
`nu_upper_bound=2` with the cost of having `rspde_order=2` and `nu_upper_bound=4`:

```{r}
# nu_upper_bound = 4
rspde_fit$cpu.used
# nu_upper_bound = 2
rspde_fit_order_3$cpu.used
```

Let us now see the summary in the original scale:

```{r summary_results_order_3}
result_fit_order_3 <- rspde.result(rspde_fit_order_3,
"field", rspde_model_order_3)
summary(result_fit_order_3)
```

Let us see the plots of the posterior marginal densities:

```{r plot_post_order_3, fig.align='center'}
par(mfrow = c(1, 3))
plot(result_fit_order_3, caption = c("tau", "kappa", "nu"))
```

One can check the order of the rational approximation by using the `rational.order()` function. It also allows another way to change the order of the rational order, 
by using the corresponding `rational.order<-()` function. 

Here to check the models:
```{r}
rational.order(rspde_model)
rational.order(rspde_model_order_3)
```

Let us now change the order of the `rspde_model` object to be 1:

```{r}
rational.order(rspde_model) <- 1
```

Let us fit this new model:

```{r fit_model_order_1, message=FALSE, warning=FALSE}
# For inlabru 2.5.3.9002 or above
 cmp.1 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model)

# For inlabru 2.5.3:
 cmp.1 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model, mapper = 
  bru_mapper(rspde_model))

rspde_fit_order_1 <- bru(cmp.1,
  family = "Gamma", data = prdata,
  options=list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(compute = TRUE),
            inla.mode = "experimental")
)
```

Here is the summary:

```{r}
summary(rspde_fit_order_1)
```

### Changing the type of the rational approximation

We have three rational approximations available. The BRASIL algorithm 
[@Hofreither21](https://doi.org/10.1007/s11075-020-01042-0), and two "versions"
of the Clenshaw-Lord Chebyshev-Pade algorithm, one with lower bound zero
and another with the lower bound given in [@xiong22](https://arxiv.org/abs/2209.04670).

The type of rational approximation can be chosen by setting the `type.rational.approx`
argument in the `rspde.matern` function. The BRASIL algorithm corresponds to the choice `brasil`,
the Clenshaw-Lord Chebyshev pade with zero lower bound and non-zero lower bounds
are given, respectively, by the choices `chebfun` and `chebfunLB`.

Let us fit a model assigning a `brasil` rational approximation. We will 
consider a model with the order of the rational approximation being 1:

```{r}
rspde_model_brasil <- rspde.matern(prmesh, rspde_order = 1,
              type.rational.approx = "brasil")

# For inlabru 2.5.3.9002 or above
cmp.1.brasil <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_brasil)

# For inlabru 2.5.3:
cmp.1.brasil <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_brasil, mapper = 
  bru_mapper(rspde_model_brasil))

rspde_fit_order_1_brasil <- bru(cmp.1.brasil,
  family = "Gamma", data = prdata,
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(compute = TRUE),
            inla.mode = "experimental")
)
```

Let us get the summary:

```{r}
summary(rspde_fit_order_1_brasil)
```

Finally, similarly to the order of the rational approximation, one can check
the order with the `rational.type()` function, and assign a new type
with the `rational.type<-()` function.

```{r}
rational.type(rspde_model)
rational.type(rspde_model_brasil)
```

Let us change the type of the rational approximation on the model with rational
approximation of order 3:

```{r}
rational.type(rspde_model_order_3) <- "brasil"

# For inlabru 2.5.3.9002 or above
cmp.3 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3)

# For inlabru 2.5.3:
cmp.3 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3, mapper = 
  bru_mapper(rspde_model_order_3))

rspde_fit_order_3_brasil <- bru(cmp.3,
  family = "Gamma", data = prdata,
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(compute = TRUE),
            inla.mode = "experimental")
)
```

Let us get the summary:

```{r}
summary(rspde_fit_order_3_brasil)
```

### Estimating models with fixed smoothness

We can fix the smoothness, say $\nu$, of the model by providing a non-NULL
positive value for `nu`.

When the smoothness, $\nu$, is fixed, we can have two possibilities:

* $\alpha = \nu + d/2$ is integer;

* $\alpha = \nu + d/2$ is not integer.

The first case, i.e., when $\alpha$ is integer, has much less computational
cost. Furthermore, the $A$ matrix is different than the $A$ matrix for the 
non-integer $\alpha$. 

If $\nu$ is fixed, we have that the parameters returned by `bru()` are
$$\kappa = \exp(\theta_1)\quad\hbox{and}\quad\tau = \exp(\theta_2).$$
We will now provide illustrations for both scenarios. 
It is also noteworthy that just as with the case in which we estimate $\nu$, we can also change
the order of the rational approximation by changing the value of `rspde_order`. 
For both illustrations with fixed $\nu$ below, we will only consider the order of the rational approximation
of 2, that is, the default order.

#### Estimating models with fixed smoothness and non-integer $\alpha$

Recall that:
$$\nu = \nu_{UB}\Big(\frac{\exp(\theta_3)}{1+\exp(\theta_3)}\Big).$$
Thus, to illustrate, let us consider a fixed $\nu$ given by the mean of $\nu$ 
obtained from the first model we considered in this vignette, namely, 
the fit given by `rspde_fit`, which is approximately $\nu = 1.21$.

Notice that for this $\nu$, the value of $\alpha$ is non-integer, so we
can use the $A$ matrix and the index of the first fitted model, 
which is also of order 2.

Therefore, all we have to do is build a new model in which we set
 `nu` to `1.21`:

```{r message=FALSE}
rspde_model_fix <- rspde.matern(mesh = prmesh, rspde_order = 2,
  nu = 1.21
)
```

Let us now fit the model:

Here we have the summary:

Now, the summary in the original scale:


#### Estimating models with fixed smoothness and integer $\alpha$

Since we are in dimension $d=2$, and $\nu>0$, the smallest value of $\nu$
that makes $\alpha = \nu + 1$ an integer is $\nu=1$. This value is also close
to the estimated mean of the first model we fitted and enclosed by the
posterior marginal density of $\nu$ for the first fit. Therefore, 
let us fit the model with $\nu=1$.

Let us create a new model (remember to set `nu=1`):

```{r message=FALSE}
rspde_model_fix_int1 <- rspde.matern(mesh = prmesh,
  nu = 1
)
```

The remaining is standard:

```{r, message=FALSE, warning=FALSE}
# For inlabru version 2.5.3.9002 and above:
cmp.int.1 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_fix_int1)

# For inlabru version 2.5.3
cmp.int.1 <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_fix_int1, mapper = 
  bru_mapper(rspde_model_fix_int1))


rspde_fix_int_1 <- bru(cmp.int.1,
  family = "Gamma",
  data = prdata,
  options = list(verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = TRUE
  ),
            inla.mode = "experimental")
)
```

Let us check the summary:

```{r}
summary(rspde_fix_int_1)
```

and check the summary in the user's scale:

```{r}
rspde_result_int <- rspde.result(rspde_fix_int_1, "field", rspde_model_fix_int1)
summary(rspde_result_int)
```

### Changing the priors

We begin by recalling that the fitted `rSPDE` model returned by `bru()` contains the 
parameters $\textrm{Theta1}$, $\textrm{Theta2}$ and $\textrm{Theta3}$. Let, again,
$\theta_1 = \textrm{Theta1}$, $\theta_2=\textrm{Theta2}$ and $\theta_3=\textrm{Theta3}$.
In terms of 
the SPDE
$$(\kappa^2 I - \Delta)^{\alpha/2}(\tau u) = \mathcal{W},$$
where $\alpha = \nu + d/2$.

#### Changing the priors of $\tau$ and $\kappa$

We begin by dealing with $\tau$ and $\kappa$. 

We have that
$$\tau = \exp(\theta_1),\quad \kappa = \exp(\theta_2).$$
The `rspde.matern()` function assumes a lognormal prior distribution for $\tau$ and $\kappa$. This prior distribution is obtained by assuming
that $\theta_1$ and $\theta_2$ follow normal distributions. By default we assume $\theta_1$ and $\theta_2$ to be independent and to follow normal
distributions $\theta_1\sim N(\log(\tau_0), 10)$ and $\theta_2\sim N(\log(\kappa_0), 10)$. 

$\kappa_0$ is suitably defined in terms of the mesh and $\tau_0$ is defined in terms of $\kappa_0$ and on 
the prior of the smoothness parameter.

If one wants to define the prior
$$\theta_1 \sim N(\text{mean_theta_1}, \text{sd_theta_1}),$$
one can simply set the argument `prior.tau = list(meanlog=mean_theta_1, sdlog=sd_theta_1)`. Analogously, to define the prior
$$\theta_2 \sim N(\text{mean_theta_2}, \text{sd_theta_2}),$$
one can set the argument `prior.kappa = list(meanlog=mean_theta_2, sdlog=sd_theta_2)`.

It is important to mention that, by default, the initial values of $\tau$ and $\kappa$
are $\exp(\text{mean_theta_1})$ and $\exp(\text{mean_theta_2})$, respectively. So,
if the user does not change these parameters, and also does not change the initial values,
the initial values of $\tau$ and $\kappa$
will be, respectively, $\tau_0$ and $\kappa_0$.

If one sets `prior.tau = list(meanlog=mean_theta_1)`, the prior for $\theta_1$ will be
$$\theta_1 \sim N(\text{mean_theta_1}, 1),$$
whereas, if one sets, `prior.tau = list(sdlog=sd_theta_1)`, the prior will be
$$\theta_1 \sim N(\log(\tau_0), \text{sd_theta_1}).$$
Analogously, if one sets  `prior.kappa = list(meanlog=mean_theta_2)`, the prior for $\theta_2$ will be
$$\theta_2 \sim N(\text{mean_theta_2}, 1),$$
whereas, if one sets, `prior.kappa = list(sdlog=sd_theta_2)`, the prior will be
$$\theta_2 \sim N(\log(\kappa_0), \text{sd_theta_2}).$$

#### Changing the prior of $\nu$

Finally, let us consider the smoothness parameter $\nu$. 

By default, we assume 
that $\nu$ follows a beta distribution on the interval $(0,\nu_{UB})$, where $\nu_{UB}$
is the upper bound for $\nu$, with mean $\nu_0=\min\{1, \nu_{UB}/2\}$ and variance $\frac{\nu_0(\nu_{UB}-\nu_0)}{1+\phi_0}$, and
we call $\phi_0$ the precision parameter, whose default value is
$$\phi_0 = \max\Big\{\frac{\nu_{UB}}{\nu_0}, \frac{\nu_{UB}}{\nu_{UB}-\nu_0}\Big\} + \phi_{inc}.$$
The parameter $\phi_{inc}$ is an increment to ensure that the prior beta density has boundary 
values equal to zero (where the boundary values are defined either by continuity or by limits). 
The default value of $\phi_{inc}$ is 1. The value of $\phi_{inc}$ can be changed by
changing the argument `nu.prec.inc` in the `rspde.matern()` function. The higher
the value of $\phi_{inc}$ (that is, the value of `nu.prec.inc`) the more informative
the prior distribution becomes.

Let us denote a beta distribution with support on $(0,\nu_{UB})$, mean $\mu$ and precision parameter $\phi$ by
$\mathcal{B}_{\nu_{UB}}(\mu,\phi)$.

If we want $\nu$ to have a prior 
$$\nu \sim \mathcal{B}_{\nu_{UB}}(\text{nu_1},\text{prec_1}),$$
one simply needs to set `prior.nu = list(mean=nu_1, prec=prec_1)`.
If one sets `prior.nu = list(mean=nu_1)`, then $\nu$ will have prior
$$\nu \sim \mathcal{B}_{\nu_{UB}}(\text{nu_1},\phi_1),$$
where
$$\phi_1 = \max\Big\{\frac{\nu_{UB}}{\text{nu_1}}, \frac{\nu_{UB}}{\nu_{UB}-\text{nu_1}}\Big\} + \text{nu.prec.inc}.$$

Of one sets `prior.nu = list(prec=prec_1)`, then $\nu$ will have prior
$$\nu\sim \mathcal{B}_{\nu_{UB}}(\nu_0, \text{prec_1}).$$
It is also noteworthy that we have that,
in terms of `r inla_link()`'s parameters,

$$\nu = \nu_{UB}\Big(\frac{\exp(\theta_3)}{1+\exp(\theta_3)}\Big).$$

It is important to mention that, by default, if a beta prior distribution is chosen for
the smoothness parameter $\nu$, then the initial value of $\nu$
is the mean of the prior beta distribution. So,
if the user does not change this parameter, and also does not change the initial value,
the initial value of $\nu$
will be $\min\{1,\nu_{UB}/2\}$.

We can have another possibility of prior distribution for $\nu$, namely, a truncated lognormal distribution.
The truncated lognormal distribution is defined
in the following sense. We assume that $\log(\nu)$ has prior distribution given by a [truncated normal distribution](https://en.wikipedia.org/wiki/Truncated_normal_distribution#One_sided_truncation_(of_upper_tail))
with support $(-\infty,\log(\nu_{UB}))$, where $\nu_{UB}$ is the upper bound for $\nu$, with location parameter $\mu_0 =\log(\nu_0)= \log\Big(\min\{1,\nu_{UB}/2\}\Big)$ and
scale parameter $\sigma_0 = 1$. More precisely, let $\Phi(\cdot; \mu,\sigma)$ stand for the cumulative distribution function (CDF) of a normal distribution
with mean $\mu$ and standard deviation $\sigma$.
Then, $\log(\nu)$ has cumulative distribution function given by
$$F_{\log(\nu)}(x) = \frac{\Phi(x;\mu_0,\sigma_0)}{\Phi(\nu_{UB})},\quad x\leq \nu_{UB},$$
and $F_{\log(\nu)}(x) = 1$ if $x>\nu_{UB}$. We will call $\mu_0$ and $\sigma_0$ the log-location and log-scale parameters of $\nu$, respectively, and we say that
$\log(\nu)$ follows a truncated normal distribution with location parameter $\mu_0$ and scale parameter $\sigma_0$.

We also assume that, in terms of `r inla_link()`'s parameters,
$$\nu = \nu_{UB}\Big(\frac{\exp(\theta_3)}{1+\exp(\theta_3)}\Big).$$

To change the prior distribution of $\nu$ to the truncated lognormal distribution, we need
to set the argument `prior.nu.dist="lognormal"`.

To change these parameters in the prior distribution to, say, `log_nu_1` and `log_sigma_1`, one can simply 
set  `prior.nu = list(loglocation=log_nu_1, logscale=sigma_1)`.

If one sets `prior.nu = list(loglocation=log_nu_1)`, the prior for $\theta_3$ will be a truncated normal 
normal distribution with location parameter `log_nu_1` and scale parameter `1`. Analogously, if one sets, `prior.nu = list(logscale=sigma_1)`, the prior for $\theta_3$ will
be a truncated normal distribution with location parameter $\log(\nu_0)= \log\Big(\min\{1,\nu_{UB}/2\}\Big)$ and scale parameter `sigma_1`.

It is important to mention that, by default, if a truncated lognormal prior distribution
is chosen for the smoothness parameter $\nu$, then the initial value of $\nu$
is the exponential of the log-location parameter of $\nu$. So,
if the user does not change this parameter, and also does not change the initial value,
the initial value of $\nu$
will be $\min\{1,\nu_{UB}/2\}$.

Let us consider an example with the same dataset used in the first model of this vignette
where we change the prior distribution of $\nu$ from beta to lognormal. Let us
also set `nu_upper_bound` to 2.

```{r}
rspde_model_ln <- rspde.matern(mesh = prmesh, prior.nu.dist = "lognormal",
  nu_upper_bound = 2
)
```

Let us create the component:
```{r}
# For inlabru 2.5.3.9002 and above:
cmp.ln <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
        field(coordinates, model = rspde_model_ln)

# For inlabru 2.5.3:alpha
cmp.ln <- y ~ Intercept(1) + distSea(seaDist, model="rw1") +
        field(coordinates, model = rspde_model_ln, mapper = 
        bru_mapper(rspde_model_ln))
```

We can now fit the model:

```{r}
rspde_fit_ln <- bru(cmp.ln,
    data = prdata,
    family = "Gamma",
options = list(verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = TRUE
  ),
            inla.mode = "experimental")
)
```

We have the summary:

```{r}
summary(rspde_fit_ln)
```

Also, we can have the summary in the user's scale:

```{r}
rspde_result_ln <- rspde.result(rspde_fit_ln, "field", rspde_model_ln)
summary(rspde_result_ln)
```

and the plot of the posterior marginal densities
```{r fig.align = "center"}
par(mfrow = c(1, 3))
plot(rspde_result_ln, caption = c("tau", "kappa", "nu"))
```

### Changing the initial values

The inital values to be used by `r inla_link()`'s optimization algorithm can be changed by
setting the arguments `start.ltau`, `start.lkappa` and `start.nu`.

* `start.ltau` will be the initial value for $\log(\tau)$, that is, the logarithm of $\tau$.

* `start.lkappa` will be the inital value for $\log(\kappa)$, that is, the logarithm of $\kappa$.

* `start.nu` will be the initial value for $\nu$. Notice that here the initial value is _not_ on the log scale.

One can change the initial value of one or more parameters.

For instance, let us consider the example with precipitation data, `rspde_order=3`, but
change the initial values to the ones close to the fitted value when considering the
default `rspde_order` (which is 2):

```{r}
rspde_model_order_3_start <- rspde.matern(mesh = prmesh, rspde_order = 3,
  nu_upper_bound = 2,
  start.lkappa = result_fit$summary.log.kappa$mean,
  start.ltau = result_fit$summary.log.tau$mean,
  start.nu = result_fit$summary.nu$mean
)
```

Let us now define the component and fit:

```{r fit_order_3_start, message=FALSE, warning=FALSE}
# For inlabru 2.5.3.9002 and above:
cmp.3.start <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3_start)

# For inlabru version 2.5.3
cmp.3.start <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_order_3_start, mapper = 
  bru_mapper(rspde_model_order_3_start))

rspde_fit_order_3_start <- bru(cmp.3.start,
  family = "Gamma",
  data = prdata,
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = TRUE
  ),
            inla.mode = "experimental")
            )
```

We have the summary:

```{r}
summary(rspde_fit_order_3_start)
```

### Choosing between the optimized and non-optimized versions

The `rspde.matern()` function has an optimized version, which is the default
and a non-optimized version.

It will take less time to fit the optimized object than to fit the non-optimized one. However
it requires a sparsity analysis when creating the model object. If the size of the
data is small it might happen that the time to analyze the sparsity plus the
time to fit the model is larger than the time to fit non-optimized model, which
does not require a sparsity analysis when creating the model object.

There is also another option for the optimized model, which is the `sharp` argument. 
The `sharp` argument is only used if `optimize` is `TRUE`.
If `sharp=TRUE` the time to fit the model is less than the time to fit a model
in which we have `sharp=FALSE`. However, the sparsity analysis takes more time
when `sharp=TRUE` than when `sharp=FALSE`.

Let us then create the three model objects with `rspde_order=1` for the precipitation
data and compare the times.

Now, let us create the three models and compute the time it took to
create the model objects:

```{r}
# Creating the optimized and sharp model
start_time <- Sys.time()
rspde_model_opt_sharp <- rspde.matern(mesh = prmesh,
  rspde_order = 1
)
end_time <- Sys.time()
time_opt_sharp <- end_time - start_time

# Creating the optimized non-sharp model
start_time <- Sys.time()
rspde_model_opt_notsharp <- rspde.matern(mesh = prmesh,
  rspde_order = 1,
  sharp = FALSE
)
end_time <- Sys.time()
time_opt_notsharp <- end_time - start_time

# Creating the non-optimized model
start_time <- Sys.time()
rspde_model_nonopt <- rspde.matern(mesh = prmesh,
  rspde_order = 1,
  optimize = FALSE
)
end_time <- Sys.time()
time_nonopt <- end_time - start_time
```

Now, let us fit the models:

```{r, message=FALSE, warning=FALSE}
# For inlabru 2.5.3.9002 and above:
cmp.opt.sharp <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_opt_sharp)

# For inlabru 2.5.3: 
cmp.opt.sharp <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_opt_sharp, mapper = 
  bru_mapper(rspde_model_opt_sharp))

rspde_fit_opt_sharp <- bru(cmp.opt.sharp,
  family = "Gamma",
  data = prdata,
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = FALSE
  ), inla.mode = "experimental")
)

# For inlabru 2.5.3.9002 and above:
cmp.opt.notsharp <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_opt_notsharp)

# For inlabru 2.5.3: 
cmp.opt.notsharp <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_opt_notsharp, mapper = 
  bru_mapper(rspde_model_opt_notsharp))

rspde_fit_opt_notsharp <- bru(cmp.opt.notsharp,
  family = "Gamma",
  data = prdata,
  options = list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = FALSE
  ),
            inla.mode = "experimental")
)

# For inlabru 2.5.3.9002 and above:
cmp.nonopt <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_nonopt)

# For inlabru 2.5.3: 
cmp.nonopt <- y ~ Intercept(1) + distSea(seaDist, model = "rw1") +
  field(coordinates, model = rspde_model_nonopt, mapper = 
  bru_mapper(rspde_model_nonopt))

rspde_fit_nonopt <- bru(cmp.nonopt,
  family = "Gamma",
  data = prdata,
  options=list(
  verbose = FALSE,
  control.inla = list(int.strategy = "eb"),
  control.predictor = list(
    compute = FALSE
  ),
            inla.mode = "experimental")
)
```

Finally, let us compare the times:

```{r}
`Time to create model` <- c(time_opt_sharp, time_opt_notsharp, time_nonopt)
`Time to fit the model` <- c(
  rspde_fit_opt_sharp$cpu.used[[2]],
  rspde_fit_opt_notsharp$cpu.used[[2]],
  rspde_fit_nonopt$cpu.used[[2]]
)
`Total time` <- `Time to create model` + `Time to fit the model`
Model <- c("Opt & sharp", "Opt & not sharp", "Non-opt")
result_table <- data.frame(
  Model, `Time to create model`,
  `Time to fit the model`,
  `Total time`
)
result_table
```

Therefore, we see that for this example one benefits from using the optimized version.


## An example with replicates

For this example we will simulate a data with replicates. We will
use the same example considered in the [Rational approximation with the `rSPDE` package](rspde_cov.html) vignette (the only difference is the way the data 
is organized).
We also refer the reader to this vignette for a description of the function
`matern.operators()`, along with its methods (for instance, the `simulate()` method).

### Simulating the data

Let us consider a simple Gaussian linear model with 30 independent replicates 
of a latent spatial field $x(\mathbf{s})$, observed at the same 
$m$ locations, $\{\mathbf{s}_1 , \ldots , \mathbf{s}_m \}$, for each replicate.
For each $i = 1,\ldots,m,$ we have

\begin{align} 
y_i &= x_1(\mathbf{s}_i)+\varepsilon_i,\\
\vdots &= \vdots\\

y_{i+29m} &= x_{30}(\mathbf{s}_i) + \varepsilon_{i+29m},
\end{align}

where $\varepsilon_1,\ldots,\varepsilon_{30m}$ are iid normally distributed
with mean 0 and standard deviation 0.1.

We use the basis function representation of $x(\cdot)$ to define the $A$ matrix
linking the point locations to the mesh. We also need to account for the fact
that we have 30 replicates at the same locations. To this end,
the $A$ matrix we need can be generated by `inla.spde.make.A()` function. The 
reason being that we are sampling $x(\cdot)$ directly and not the
latent vector described in the introduction of the 
[Rational approximation with the `rSPDE` package](rspde_cov.html) vignette.

We begin by creating the mesh:

```{r fig.align = "center"}
m <- 200
loc_2d_mesh <- matrix(runif(m * 2), m, 2)
mesh_2d <- inla.mesh.2d(
  loc = loc_2d_mesh,
  cutoff = 0.05,
  offset = c(0.1, 0.4),
  max.edge = c(0.05, 0.5)
)
plot(mesh_2d, main = "")
points(loc_2d_mesh[, 1], loc_2d_mesh[, 2])
```

We then compute the $A$ matrix, which is needed for simulation, and connects the observation
locations to the mesh:

```{r}
n.rep <- 30
A <- inla.spde.make.A(
  mesh = mesh_2d,
  loc = loc_2d_mesh,
  index = rep(1:m, times = n.rep),
  repl = rep(1:n.rep, each = m)
)
```

Notice that for the simulated data, we should use the $A$ matrix from `inla.spde.make.A()` function.

We will now simulate a latent process with standard deviation $\sigma=1$ and 
range $0.1$. We will use $\nu=0.5$ so that the model has an exponential covariance function.
To this end we create a model object with the `matern.operators()` function:

```{r}
nu <- 0.5
sigma <- 1
range <- 0.1
kappa <- sqrt(8 * nu) / range
tau <- sqrt(gamma(nu) / (sigma^2 * kappa^(2 * nu) * (4 * pi) * gamma(nu + 1)))
d <- 2
operator_information <- matern.operators(
  mesh = mesh_2d,
  nu = nu,
  kappa = kappa,
  sigma = sigma,
  m = 2
)
```
More details on this function can be found at the [Rational approximation with the rSPDE package](rspde_cov.html) vignette.

To simulate the latent process all we need to do is to use the `simulate()` method on
the `operator_information` object. We then obtain the simulated data $y$
by connecting with the $A$ matrix and adding the gaussian noise.

```{r}
set.seed(1)
u <- simulate(operator_information, nsim = n.rep)
y <- as.vector(A %*% as.vector(u)) +
  rnorm(m * n.rep) * 0.1
```

The first replicate of the simulated random field as well as the observation locations are shown in the following figure.

```{r, fig.show='hold', fig.align = "center",echo=FALSE}
opar <- par(mfrow = c(1, 2), mgp = c(1.2, 0.5, 0),
   mar = c(2, 2, 0.5, 0.5) + 0.1)
proj <- inla.mesh.projector(mesh_2d, dims = c(100, 100))
image(inla.mesh.project(proj, field = as.vector(u[, 1])),
  xlab = "", ylab = "",
  cex.main = 0.8, cex.axis = 0.8, cex.lab = 0.8
)
plot(loc_2d_mesh[, 1], loc_2d_mesh[, 2],
  cex = 0.2, pch = 16, xlab = "", ylab = "",
  cex.main = 0.8, cex.axis = 0.8, cex.lab = 0.8
)
par(opar)
```


### Fitting the `inlabru` rSPDE model

Let us then use the rational SPDE approach to fit the data.

We begin by creating the model object. 

```{r}
rspde_model.rep <- rspde.matern(mesh = mesh_2d) 
```

Let us now create the `data.frame()` and the vector with the replicates indexes:

```{r}
rep.df <- data.frame(y = y, x1 = rep(loc_2d_mesh[,1], 30),
                      x2 = rep(loc_2d_mesh[,2], 30))
coordinates(rep.df) <- c("x1", "x2")
repl <- rep(1:30, each=200)
```

Let us create the component and fit. It is extremely important
not to forget the `replicate` when fitting model with 
the `bru()` function. It will not produce warning and might fit some
meaningless model.

```{r, message=FALSE, warning=FALSE}
# For inlabru 2.5.3.9002 or above:
cmp.rep <-
  y ~ -1 + field(coordinates,
    model = rspde_model.rep,
    replicate = repl
  )

# For inlabru 2.5.3
cmp.rep <-
  y ~ -1 + field(coordinates,
    model = rspde_model.rep,
    replicate = repl,
    mapper = bru_mapper(rspde_model.rep)
  )


rspde_fit.rep <-
  bru(cmp.rep,
    data = rep.df,
    family = "gaussian",
    options = list(
      list(inla.mode = "experimental")
    )
  )
```

We can get the summary:
```{r}
summary(rspde_fit.rep)
```

and the summary in the user's scale:
```{r}
result_fit_rep <- rspde.result(rspde_fit.rep, "field", rspde_model.rep)
summary(result_fit_rep)
result_df <- data.frame(
  parameter = c("tau", "kappa", "nu"),
  true = c(tau, kappa, nu),
  mean = c(
    result_fit_rep$summary.tau$mean,
    result_fit_rep$summary.kappa$mean,
    result_fit_rep$summary.nu$mean
  ),
  mode = c(
    result_fit_rep$summary.tau$mode,
    result_fit_rep$summary.kappa$mode,
    result_fit_rep$summary.nu$mode
  )
)
print(result_df)
```

## References 
